import asyncio
from typing import Dict, Any, List, Optional, Tuple
from processor import llm_handler
from services.db_service import db_service
import concurrent.futures
import math
import time


MAX_CHUNK_SIZE = 30

class AnalysisService:
    def __init__(self):
        self.metrics_cache = {}
    
    async def process_batch(self, session_id: str, telegram_user_id: int, interlocutor_id: int, messages: List[Dict[str, Any]]):
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–π –±–∞—Ç—á —Å–æ–æ–±—â–µ–Ω–∏–π, –≤—ã–ø–æ–ª–Ω—è—è –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            telegram_user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–µ–ª–µ–≥—Ä–∞–º
            interlocutor_id: ID —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            print(f"üìù –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ —Å–µ—Å—Å–∏–∏ {session_id}, —á–∞—Ç–∞ {interlocutor_id}, —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {len(messages)}")
            

            if len(messages) > MAX_CHUNK_SIZE:
                chunks = self._split_messages_into_chunks(messages, MAX_CHUNK_SIZE)
                print(f"üîÑ –ë–æ–ª—å—à–æ–π –±–∞—Ç—á —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π –ø–æ ~{MAX_CHUNK_SIZE} —Å–æ–æ–±—â–µ–Ω–∏–π")
                

                compliments_results = {}
                engagement_results = {}
                attachment_results = {}
                

                historical_summary = await db_service.get_historical_summary(session_id, interlocutor_id)
                print(f"üìö –ü–æ–ª—É—á–µ–Ω–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å–∞–º–º–µ—Ä–∏, –¥–ª–∏–Ω–∞: {len(historical_summary) if historical_summary else 0} —Å–∏–º–≤–æ–ª–æ–≤")
                

                for i, chunk in enumerate(chunks):
                    print(f"üß© –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç—å {i+1}/{len(chunks)}, —Ä–∞–∑–º–µ—Ä: {len(chunk)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                    

                    if i % 3 == 0 and i > 0:
                        pass
                    

                    try:

                        if i > 0:
                            delay = 2.0
                            print(f"‚è±Ô∏è –ñ–¥–µ–º {delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–ª–µ–¥—É—é—â–µ–≥–æ —á–∞–Ω–∫–∞...")
                            await asyncio.sleep(delay)
                        
                        compliments, engagement, attachment = await self._get_metrics_for_chunk(chunk, historical_summary)
                        

                        if compliments:
                            for sender, count in compliments.items():
                                if sender in compliments_results:
                                    compliments_results[sender] += count
                                else:
                                    compliments_results[sender] = count
                        
                        if engagement:
                            for sender, score in engagement.items():
                                if sender in engagement_results:

                                    engagement_results[sender] = (engagement_results[sender] + score) / 2
                                else:
                                    engagement_results[sender] = score
                        
                        if attachment:
                            for sender, data in attachment.items():
                                if sender not in attachment_results:
                                    attachment_results[sender] = data
                                elif data.get("confidence", 0) > attachment_results[sender].get("confidence", 0):

                                    attachment_results[sender] = data
                                    
                        print(f"‚úÖ –ß–∞—Å—Ç—å {i+1} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞—Å—Ç–∏ {i+1}: {e}")
                        import traceback
                        print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
                

                print(f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–≥–æ –±–∞—Ç—á–∞")
                await self._generate_user_recommendations(session_id, telegram_user_id, interlocutor_id, messages, historical_summary or "")
                


                last_chunk_size = min(MAX_CHUNK_SIZE, len(messages))
                last_messages = messages[-last_chunk_size:]
                print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º —Å–∞–º–º–µ—Ä–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {len(last_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                await self._update_summary(session_id, interlocutor_id, last_messages, historical_summary)
                
            else:


                historical_summary = await db_service.get_historical_summary(session_id, interlocutor_id)
                print(f"üìö –ü–æ–ª—É—á–µ–Ω–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å–∞–º–º–µ—Ä–∏, –¥–ª–∏–Ω–∞: {len(historical_summary) if historical_summary else 0} —Å–∏–º–≤–æ–ª–æ–≤")
                

                print(f"üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –±–∞—Ç—á–∞ –∏–∑ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                


                print(f"üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏...")
                await self._analyze_metrics(session_id, telegram_user_id, interlocutor_id, messages, historical_summary)
                
                print(f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_user_id}")
                await self._generate_user_recommendations(session_id, telegram_user_id, interlocutor_id, messages, historical_summary or "")
                

                print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º —Å–∞–º–º–µ—Ä–∏ –¥–∏–∞–ª–æ–≥–∞")
                await self._update_summary(session_id, interlocutor_id, messages, historical_summary)
            

            print(f"üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –ë–î")
            await self.flush_metrics()
            
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å–µ—Å—Å–∏–∏ {session_id}, —á–∞—Ç–∞ {interlocutor_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞: {e}")

            import traceback
            print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
    
    async def _check_network_connection(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–µ—Ç–µ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ"""
        try:
            print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –±–µ–∑ DNS-–ø—Ä–æ–≤–µ—Ä–æ–∫")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–µ—Ç–∏: {e}")
            import traceback
            print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ—Ç–∏:\n{traceback.format_exc()}")
    
    def _split_messages_into_chunks(self, messages: List[Dict[str, Any]], chunk_size: int) -> List[List[Dict[str, Any]]]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –±–æ–ª—å—à–æ–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ —á–∞—Å—Ç–∏
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è
            chunk_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–π —á–∞—Å—Ç–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞—Å—Ç–µ–π —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        """
        total_chunks = math.ceil(len(messages) / chunk_size)
        return [messages[i*chunk_size:(i+1)*chunk_size] for i in range(total_chunks)]
    
    async def _get_metrics_for_chunk(self, messages: List[Dict[str, Any]], historical_summary: Optional[str]):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —á–∞—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            historical_summary: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å–∞–º–º–µ—Ä–∏
            
        Returns:
            Tuple –∏–∑ (compliments, engagement, attachment)
        """
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as pool:

            start_time = time.time()
            

            current_loop = asyncio.get_running_loop()
            
            print(f"üîÑ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã –¥–ª—è {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            compliments_future = current_loop.run_in_executor(
                pool, 
                lambda: llm_handler.count_compliments(messages)
            )
            
            print(f"üîÑ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            engagement_future = current_loop.run_in_executor(
                pool, 
                lambda: llm_handler.calculate_engagement(messages, historical_summary or "", max_retries=3)
            )
            
            print(f"üîÑ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–∏–ø –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            attachment_future = current_loop.run_in_executor(
                pool, 
                lambda: llm_handler.calculate_attachment(messages, historical_summary or "", max_retries=3)
            )
            

            compliments, engagement, attachment = await asyncio.gather(
                compliments_future, engagement_future, attachment_future
            )
            

            compliments = compliments or {}
            engagement = engagement or {}
            attachment = attachment or {}
            
            elapsed_time = time.time() - start_time
            print(f"‚è±Ô∏è –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∑–∞–Ω—è–ª–æ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            return compliments, engagement, attachment
    
    async def _update_summary(self, session_id: str, interlocutor_id: int, messages: List[Dict[str, Any]], historical_summary: Optional[str]) -> str:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å–∞–º–º–µ—Ä–∏"""
        try:

            current_loop = asyncio.get_running_loop()
            
            print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º —Å–∞–º–º–µ—Ä–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            new_summary = await current_loop.run_in_executor(
                None,
                lambda: llm_handler.update_summary(messages, historical_summary)
            )
            
            if new_summary:
                await db_service.save_historical_summary(session_id, interlocutor_id, new_summary)
                print(f"‚úÖ –°–∞–º–º–µ—Ä–∏ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}, —á–∞—Ç–∞ {interlocutor_id} –æ–±–Ω–æ–≤–ª–µ–Ω–æ")
                return new_summary
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–∞–º–º–µ—Ä–∏: {e}")
            import traceback
            print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏ —Å–∞–º–º–µ—Ä–∏:\n{traceback.format_exc()}")
        return historical_summary or ""
    
    async def _analyze_metrics(self, session_id: str, telegram_user_id: int, interlocutor_id: int, 
                         messages: List[Dict[str, Any]], historical_summary: Optional[str]):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–∏–∞–ª–æ–≥–∞"""
        try:

            user_messages = [m for m in messages if str(m['SenderId']) == str(telegram_user_id)]
            interlocutor_messages = [m for m in messages if str(m['SenderId']) == str(interlocutor_id)]
            
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π:")
            print(f"  - –û—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_user_id}: {len(user_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            print(f"  - –û—Ç —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ {interlocutor_id}: {len(interlocutor_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            

            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as pool:

                current_loop = asyncio.get_running_loop()
                
                print(f"üîÑ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã –¥–ª—è {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                compliments_future = current_loop.run_in_executor(
                    pool, 
                    lambda: llm_handler.count_compliments(messages)
                )
                
                print(f"üîÑ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                engagement_future = current_loop.run_in_executor(
                    pool, 
                    lambda: llm_handler.calculate_engagement(messages, historical_summary or "", max_retries=3)
                )
                
                print(f"üîÑ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–∏–ø –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                attachment_future = current_loop.run_in_executor(
                    pool, 
                    lambda: llm_handler.calculate_attachment(messages, historical_summary or "", max_retries=3)
                )
                

                compliments, engagement, attachment = await asyncio.gather(
                    compliments_future, engagement_future, attachment_future
                )
            

            compliments = compliments or {}
            engagement = engagement or {}
            attachment = attachment or {}
            
            if not compliments and not engagement and not attachment:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏")
                return
            

            print(f"üìä –ü–æ–ª—É—á–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏: –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã={compliments}, –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å={engagement}")
            

            previous_engagement = {}
            for sender_id in [telegram_user_id, interlocutor_id]:
                role = "user" if str(sender_id) == str(telegram_user_id) else "interlocutor"
                prev_metrics = await db_service.get_latest_metrics(session_id, interlocutor_id, role)
                if prev_metrics:
                    previous_engagement[str(sender_id)] = prev_metrics.get("engagement_score", 0)


            engagement = llm_handler.calculate_engagement(messages, historical_summary, previous_engagement, max_retries=3) or {}
            

            previous_attachments = {}
            for sender_id in [telegram_user_id, interlocutor_id]:
                role = "user" if str(sender_id) == str(telegram_user_id) else "interlocutor"
                prev_metrics = await db_service.get_latest_metrics(session_id, interlocutor_id, role)
                if prev_metrics:
                    previous_attachments[str(sender_id)] = {
                        "type": prev_metrics.get("attachment_type", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                        "confidence": prev_metrics.get("attachment_confidence", 0) * 100
                    }


            for sender_id in set(list(compliments.keys()) + list(engagement.keys()) + list(attachment.keys())):

                role = "user" if str(sender_id) == str(telegram_user_id) else "interlocutor"
                

                participant_messages = user_messages if role == "user" else interlocutor_messages
                if not participant_messages:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è {role} ({sender_id}): –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π")
                    continue
                

                previous_metrics = await db_service.get_latest_metrics(session_id, interlocutor_id, role)
                previous_total = previous_metrics.get('total_compliments', 0) if previous_metrics else 0
                

                compliment_count = compliments.get(str(sender_id), 0)
                

                compliments_delta = compliment_count
                new_total = previous_total + compliments_delta
                
                print(f"–ö–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã –¥–ª—è {role} ({sender_id}):")
                print(f"  - –ù–∞–π–¥–µ–Ω–æ –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ: {compliment_count}")
                print(f"  - –ü—Ä–µ–¥—ã–¥—É—â–µ–µ total_compliments: {previous_total}")
                print(f"  - –°–æ—Ö—Ä–∞–Ω—è–µ–º delta: {compliments_delta}")
                print(f"  - –ù–æ–≤–æ–µ total: {new_total}")
                

                att = attachment.get(str(sender_id), {})
                att_type = att.get("type") or "unknown"
                att_conf = att.get("confidence") or 0
                if att_type in [None, "", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"]:
                    att_type = "unknown"
                

                cache_key = f"{session_id}:{interlocutor_id}:{role}"
                self.metrics_cache[cache_key] = {
                    "session_id": session_id,
                    "telegram_user_id": telegram_user_id,
                    "interlocutor_id": interlocutor_id,
                    "role": role,
                    "compliments_delta": compliments_delta,
                    "total_compliments": new_total,
                    "engagement_score": engagement.get(str(sender_id), 0),
                    "attachment_type": att_type if att_type != "unknown" else "",
                    "attachment_confidence": att_conf / 100
                }
                print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {role} ({sender_id}) –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –∫—ç—à")
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –º–µ—Ç—Ä–∏–∫: {e}")
            import traceback
            print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏ –º–µ—Ç—Ä–∏–∫:\n{traceback.format_exc()}")
    
    async def _generate_user_recommendations(self, session_id: str, telegram_user_id: int, 
                                     interlocutor_id: int, messages: List[Dict[str, Any]], 
                                     historical_summary: str):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:

            current_loop = asyncio.get_running_loop()
            

            if len(messages) > MAX_CHUNK_SIZE:
                print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {MAX_CHUNK_SIZE} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                messages_for_recommendations = messages[-MAX_CHUNK_SIZE:]
            else:
                messages_for_recommendations = messages
                
            print(f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(messages_for_recommendations)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            recommendations = await current_loop.run_in_executor(
                None,
                lambda: llm_handler.generate_recommendations(messages_for_recommendations, historical_summary, str(telegram_user_id))
            )
            
            if recommendations:

                print(f"üîÑ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_user_id} –≤ –ë–î")
                save_result = await db_service.save_user_recommendation(
                    session_id, 
                    telegram_user_id, 
                    interlocutor_id, 
                    recommendations
                )
                if save_result:
                    print(f"‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_user_id} —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
                else:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_user_id} –≤ –ë–î")
            else:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_user_id}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            import traceback
            print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:\n{traceback.format_exc()}")
    
    async def flush_metrics(self):
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –º–æ–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
        """
        metrics_to_save = self.metrics_cache.copy()
        print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ –ë–î, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç—Ä–∏–∫ –≤ –∫—ç—à–µ: {len(metrics_to_save)}")
        self.metrics_cache.clear()
        
        for cache_key, metrics in metrics_to_save.items():
            try:
                print(f"üîÑ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {cache_key}:")
                print(f"  - session_id: {metrics['session_id']}")
                print(f"  - role: {metrics['role']}")
                print(f"  - compliments_delta: {metrics['compliments_delta']}")
                print(f"  - total_compliments: {metrics['total_compliments']}")
                print(f"  - engagement_score: {metrics['engagement_score']}")
                print(f"  - attachment_type: {metrics['attachment_type']}")
                print(f"  - attachment_confidence: {metrics['attachment_confidence']}")
                
                await db_service.save_chat_metrics(
                    metrics["session_id"],
                    metrics["telegram_user_id"],
                    metrics["interlocutor_id"],
                    metrics["role"],
                    metrics["compliments_delta"],
                    metrics["total_compliments"],
                    metrics["engagement_score"],
                    metrics["attachment_type"],
                    metrics["attachment_confidence"]
                )
                print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {cache_key} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –¥–ª—è {cache_key}: {e}")
                import traceback
                print(f"–°—Ç–µ–∫ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")

                self.metrics_cache[cache_key] = metrics


analysis_service = AnalysisService() 